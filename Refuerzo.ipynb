{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dtxYLfTp5-Zk",
        "outputId": "282002c1-4607-41fb-a180-c74568959e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episodio 1\n",
            "(0,0): [-0.1 -0.1  0.   0. ]\n",
            "(0,1): [-0.1        41.76600685 -1.          0.        ]\n",
            "(0,2): [94.8947431   1.92623371  4.11849105  8.9082112 ]\n",
            "(0,3): [-0.19       -0.1        -1.         24.12835303]\n",
            "(0,4): [-0.199 -0.199 -0.1   -0.1  ]\n",
            "(1,0): [0. 0. 0. 0.]\n",
            "(1,1): [1.47133326 0.         0.         0.        ]\n",
            "(1,2): [22.9048664 -1.         0.         0.       ]\n",
            "(1,3): [-0.1 -0.1  0.   0. ]\n",
            "(1,4): [-0.199 -0.1    1.9    0.   ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-0.01  1.    5.    0.  ]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 2\n",
            "(0,0): [-0.199       3.56894062 -0.1        -0.1       ]\n",
            "(0,1): [-0.1        52.16299654 -1.          0.        ]\n",
            "(0,2): [97.23455853  6.1508171   4.11849105 12.15908406]\n",
            "(0,3): [-0.19       -0.199      -1.         31.40190224]\n",
            "(0,4): [-0.199 -0.199 -0.019 -0.1  ]\n",
            "(1,0): [-0.1  0.   0.   0. ]\n",
            "(1,1): [1.47133326 0.         0.         0.        ]\n",
            "(1,2): [22.9048664 -1.         0.         0.       ]\n",
            "(1,3): [-0.1 -0.1  0.   0. ]\n",
            "(1,4): [-0.199 -0.1    3.16   0.   ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-0.01  1.    9.5   0.  ]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 3\n",
            "(0,0): [-0.199       7.80671624 -0.1        -0.1       ]\n",
            "(0,1): [-0.1        84.68747438 -1.          0.        ]\n",
            "(0,2): [99.96809999 55.50606634 22.48256858 46.95914302]\n",
            "(0,3): [-0.19      -0.28081   -1.        87.0605385]\n",
            "(0,4): [-0.199  -0.199   0.1673 -0.1   ]\n",
            "(1,0): [-0.1  0.   0.   0. ]\n",
            "(1,1): [1.47133326 0.         0.         0.        ]\n",
            "(1,2): [62.9083877 -1.         0.         0.       ]\n",
            "(1,3): [-0.1 -0.1  0.   0. ]\n",
            "(1,4): [-0.199 -0.1    4.699  0.   ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-1.000e-02  1.000e+00  1.355e+01  0.000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 4\n",
            "(0,0): [-0.199      20.87651244 -0.1        -0.1       ]\n",
            "(0,1): [ 8.37731415 96.10579792 -1.          1.20931256]\n",
            "(0,2): [99.99993533 81.85787797 55.06234042 72.45375758]\n",
            "(0,3): [-0.19      -0.337672  -1.9       98.4252051]\n",
            "(0,4): [-0.199   -0.199    0.47348 -0.1    ]\n",
            "(1,0): [-0.1  0.   0.   0. ]\n",
            "(1,1): [1.47133326 0.         0.         0.        ]\n",
            "(1,2): [87.0652086  -1.15225733  0.          0.        ]\n",
            "(1,3): [16.13740867 -0.1         0.          0.        ]\n",
            "(1,4): [-0.199  -0.1     6.4486  0.    ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-1.0000e-02  1.0000e+00  1.7195e+01  0.0000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 5\n",
            "(0,0): [-0.199      27.33838301 -0.1        -0.1       ]\n",
            "(0,1): [ 8.37731415 96.49521231 -1.          1.20931256]\n",
            "(0,2): [99.9999639  82.43035863 57.29197515 72.45375758]\n",
            "(0,3): [-0.19      -0.3612916 -1.9       98.4252051]\n",
            "(0,4): [-0.199    -0.199     0.906506 -0.1     ]\n",
            "(1,0): [-0.1  0.   0.   0. ]\n",
            "(1,1): [1.47133326 0.         0.         0.        ]\n",
            "(1,2): [88.35868422 -1.15225733  0.          0.        ]\n",
            "(1,3): [16.13740867 -0.1         0.          0.        ]\n",
            "(1,4): [-0.199   -0.1      8.35129  0.     ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-1.00000e-02  1.00000e+00  2.04755e+01  0.00000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 6\n",
            "(0,0): [-0.199      33.18911382 -0.1        -0.1       ]\n",
            "(0,1): [ 8.37731415 97.44500265 -1.          1.20931256]\n",
            "(0,2): [99.99998596 84.65574068 63.33889344 75.0865448 ]\n",
            "(0,3): [-0.19       -0.3435769  -1.9        98.96677059]\n",
            "(0,4): [-0.199      -0.199       1.97234045 -0.1       ]\n",
            "(1,0): [-0.1  0.   0.   0. ]\n",
            "(1,1): [1.47133326 0.         0.         0.        ]\n",
            "(1,2): [91.51347482 -1.15225733  0.          0.        ]\n",
            "(1,3): [16.13740867 -0.1         0.          0.        ]\n",
            "(1,4): [-0.14702756  0.5616161  10.358956    0.        ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-1.000000e-02  1.000000e+00  2.342795e+01  0.000000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 7\n",
            "(0,0): [-0.199      43.39996791 -0.1        -0.1       ]\n",
            "(0,1): [ 8.37731415 99.01013955 -1.          4.45700404]\n",
            "(0,2): [99.99999874 86.12970218 76.09929174 81.59734354]\n",
            "(0,3): [-0.19       -0.23170857 -1.9        99.32209703]\n",
            "(0,4): [-0.199      -0.199       2.60741245 -0.1       ]\n",
            "(1,0): [-0.1  0.   0.   0. ]\n",
            "(1,1): [10.101995  0.        0.        0.      ]\n",
            "(1,2): [96.34682617 -1.15225733  0.         -0.86758001]\n",
            "(1,3): [16.13740867 -0.1         0.          0.        ]\n",
            "(1,4): [-0.14702756  0.5616161  12.4315759   0.        ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [0. 0. 0. 0.]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-1.0000000e-02  1.0000000e+00  2.6085155e+01  0.0000000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 8\n",
            "(0,0): [-0.199      67.10654916 -0.1         5.11710548]\n",
            "(0,1): [23.67721322 99.99999979  9.03221738 26.29962852]\n",
            "(0,2): [100.          88.99999754  88.99998114  88.99999301]\n",
            "(0,3): [ 1.67558140e+01 -7.38705925e-02  1.54726453e+01  9.99999999e+01]\n",
            "(0,4): [-0.199      -0.199       3.36551303 -0.1       ]\n",
            "(1,0): [-0.1         3.23487228  0.          0.        ]\n",
            "(1,1): [61.47931818  0.          0.         -0.1       ]\n",
            "(1,2): [99.99999823 10.05460327  4.9152561  11.01726713]\n",
            "(1,3): [66.10892575  0.92884183  0.          0.        ]\n",
            "(1,4): [-0.14702756  0.5616161  14.53608226  3.13339998]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [23.90016171  0.          0.          0.        ]\n",
            "(2,3): [0. 0. 0. 0.]\n",
            "(2,4): [-1.00000000e-02  1.00000000e+00  2.84766395e+01  0.00000000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 9\n",
            "(0,0): [-0.199      69.29589422 -0.1         5.11710548]\n",
            "(0,1): [23.67721322 99.99999998  9.03221738 26.29962852]\n",
            "(0,2): [100.          88.99999993  88.99999665  88.99999934]\n",
            "(0,3): [ 16.75581396   0.4041202   15.47264533 100.        ]\n",
            "(0,4): [-0.199      -0.199       5.02173562 -0.1       ]\n",
            "(1,0): [-0.1         3.23487228  0.          0.        ]\n",
            "(1,1): [61.47931818  0.          0.         -0.1       ]\n",
            "(1,2): [99.9999997  14.20496593  4.9152561  11.01726713]\n",
            "(1,3): [70.45822985  0.92884183 -0.1         0.        ]\n",
            "(1,4): [-0.14702756  0.5616161  16.64537159  7.7698633 ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [23.90016171  0.          0.          0.        ]\n",
            "(2,3): [5.15582299 0.         0.         0.        ]\n",
            "(2,4): [-1.00000000e-02  1.00000000e+00  3.06289755e+01  0.00000000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n",
            "\n",
            "Episodio 10\n",
            "(0,0): [-0.199      73.03967432 -0.1         5.11710548]\n",
            "(0,1): [ 36.08854271 100.          12.66213428  29.9836331 ]\n",
            "(0,2): [100.         89.         88.9999999  89.       ]\n",
            "(0,3): [ 30.4822093    0.71566438  28.98738193 100.        ]\n",
            "(0,4): [-0.199     -0.199      5.9176455 -0.1      ]\n",
            "(1,0): [-0.1         3.23487228  0.          0.        ]\n",
            "(1,1): [64.23138637  0.          0.         -0.1       ]\n",
            "(1,2): [99.99999999 14.20496593 10.55418364 11.01726713]\n",
            "(1,3): [75.48304956  0.92884183 -0.1         8.89999998]\n",
            "(1,4): [-0.14702756  0.5616161  18.73744223  7.7698633 ]\n",
            "(2,0): [0. 0. 0. 0.]\n",
            "(2,1): [0. 0. 0. 0.]\n",
            "(2,2): [36.26913098  0.          0.          0.        ]\n",
            "(2,3): [5.15582299 0.         0.         0.        ]\n",
            "(2,4): [-1.0000000e-02  1.0000000e+00  3.2566078e+01  0.0000000e+00]\n",
            "(3,0): [0. 0. 0. 0.]\n",
            "(3,1): [0. 0. 0. 0.]\n",
            "(3,2): [0. 0. 0. 0.]\n",
            "(3,3): [0. 0. 0. 0.]\n",
            "(3,4): [0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parámetros\n",
        "rows, cols = 4, 5\n",
        "actions = ['U', 'R', 'D', 'L']\n",
        "alpha = 0.1\n",
        "gamma = 0.9\n",
        "epsilon = 0.1\n",
        "episodes = 10\n",
        "\n",
        "# Inicializa Q-table\n",
        "Q = np.zeros((rows, cols, len(actions)))\n",
        "\n",
        "# Define un entorno sencillo\n",
        "def step(state, action):\n",
        "    i, j = state\n",
        "    if action == 0: i = max(i-1, 0)       # up\n",
        "    elif action == 1: j = min(j+1, cols-1) # right\n",
        "    elif action == 2: i = min(i+1, rows-1) # down\n",
        "    elif action == 3: j = max(j-1, 0)      # left\n",
        "    # definir recompensas arbitrarias:\n",
        "    if (i, j) == (3,4): return (i,j), 50, True  # END\n",
        "    elif (i,j) in [(1,1),(1,3),(3,0),(3,3)]: return (i,j), -10, False # mines\n",
        "    elif (i,j) in [(0,2),(2,2),(2,4),(3,2)]: return (i,j), +10, False # power\n",
        "    else: return (i,j), -1, False # paso normal\n",
        "\n",
        "# Ciclo de episodios\n",
        "for ep in range(episodes):\n",
        "    state = (0,0)\n",
        "    done = False\n",
        "    while not done:\n",
        "        # elegir acción epsilon-greedy\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.choice(4)\n",
        "        else:\n",
        "            action = np.argmax(Q[state[0], state[1], :])\n",
        "\n",
        "        # ejecutar acción\n",
        "        next_state, reward, done = step(state, action)\n",
        "\n",
        "        # actualizar Q-table\n",
        "        best_next_q = np.max(Q[next_state[0], next_state[1], :])\n",
        "        Q[state[0], state[1], action] += alpha * (\n",
        "            reward + gamma * best_next_q - Q[state[0], state[1], action]\n",
        "        )\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # Pintar Q-table después de cada episodio\n",
        "    print(f\"\\nEpisodio {ep+1}\")\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            q_vals = Q[i,j]\n",
        "            print(f\"({i},{j}): {q_vals}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class DQNCNN(nn.Module):\n",
        "    def __init__(self, n_actions):\n",
        "        super(DQNCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(4, 32, kernel_size=8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, 512), nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Ejemplo de uso\n",
        "n_actions = 3\n",
        "model = DQNCNN(n_actions)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Supón que tienes:\n",
        "state = torch.rand((1,4,84,84))  # estado (batch, canales, alto, ancho)\n",
        "target_q = torch.tensor([[1.0, 0.0, -1.0]])  # valores objetivo para este estado\n",
        "\n",
        "# Predicción y pérdida\n",
        "predicted_q = model(state)\n",
        "loss = loss_fn(predicted_q, target_q)\n",
        "\n",
        "# Backpropagation\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "id": "60TaK-guICpM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "from math import ceil,floor\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "CUydCtYaKymM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PongAgent:\n",
        "\n",
        "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
        "\n",
        "        # Creamos la tabla de politicas\n",
        "        if policy is not None:\n",
        "            self._q_table = policy\n",
        "        else:\n",
        "            position = list(game.positions_space.shape)\n",
        "            position.append(len(game.action_space))\n",
        "            self._q_table = np.zeros(position)\n",
        "\n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ratio_explotacion = ratio_explotacion\n",
        "\n",
        "    def get_next_step(self, state, game):\n",
        "\n",
        "        # Damos un paso aleatorio...\n",
        "        next_step = np.random.choice(list(game.action_space))\n",
        "\n",
        "        # o tomaremos el mejor paso...\n",
        "        if np.random.uniform() <= self.ratio_explotacion:\n",
        "            # tomar el maximo\n",
        "            idx_action = np.random.choice(np.flatnonzero(\n",
        "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
        "                ))\n",
        "            next_step = list(game.action_space)[idx_action]\n",
        "\n",
        "        return next_step\n",
        "\n",
        "    # actualizamos las politicas con las recompensas obtenidas\n",
        "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
        "        idx_action_taken =list(game.action_space).index(action_taken)\n",
        "\n",
        "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
        "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
        "\n",
        "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
        "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
        "        if reached_end:\n",
        "            future_max_q_value = reward_action_taken #maximum reward\n",
        "\n",
        "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
        "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
        "\n",
        "    def print_policy(self):\n",
        "        for row in np.round(self._q_table,1):\n",
        "            for column in row:\n",
        "                print('[', end='')\n",
        "                for value in column:\n",
        "                    print(str(value).zfill(5), end=' ')\n",
        "                print('] ', end='')\n",
        "            print('')\n",
        "\n",
        "    def get_policy(self):\n",
        "        return self._q_table"
      ],
      "metadata": {
        "id": "Qi7JuwgvK2ri"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PongEnvironment:\n",
        "\n",
        "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
        "\n",
        "        self.action_space = ['Arriba','Abajo']\n",
        "\n",
        "        self._step_penalization = 0\n",
        "\n",
        "        self.state = [0,0,0]\n",
        "\n",
        "        self.total_reward = 0\n",
        "\n",
        "        self.dx = movimiento_px\n",
        "        self.dy = movimiento_px\n",
        "\n",
        "        filas = ceil(height_px/movimiento_px)\n",
        "        columnas = ceil(width_px/movimiento_px)\n",
        "\n",
        "        self.positions_space = np.array([[[0 for z in range(columnas)]\n",
        "                                                  for y in range(filas)]\n",
        "                                                     for x in range(filas)])\n",
        "\n",
        "        self.lives = max_life\n",
        "        self.max_life=max_life\n",
        "\n",
        "        self.x = randint(int(width_px/2), width_px)\n",
        "        self.y = randint(0, height_px-10)\n",
        "\n",
        "        self.player_alto = int(height_px/4)\n",
        "\n",
        "        self.player1 = self.player_alto  # posic. inicial del player\n",
        "\n",
        "        self.score = 0\n",
        "\n",
        "        self.width_px = width_px\n",
        "        self.height_px = height_px\n",
        "        self.radio = 2.5\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_reward = 0\n",
        "        self.state = [0,0,0]\n",
        "        self.lives = self.max_life\n",
        "        self.score = 0\n",
        "        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "        self.y = randint(0, self.height_px-10)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, animate=False):\n",
        "        self._apply_action(action, animate)\n",
        "        done = self.lives <=0 # final\n",
        "        reward = self.score\n",
        "        reward += self._step_penalization\n",
        "        self.total_reward += reward\n",
        "        return self.state, reward , done\n",
        "\n",
        "    def _apply_action(self, action, animate=False):\n",
        "\n",
        "        if action == \"Arriba\":\n",
        "            self.player1 += abs(self.dy)\n",
        "        elif action == \"Abajo\":\n",
        "            self.player1 -= abs(self.dy)\n",
        "\n",
        "        self.avanza_player()\n",
        "\n",
        "        self.avanza_frame()\n",
        "\n",
        "        if animate:\n",
        "            clear_output(wait=True);\n",
        "            fig = self.dibujar_frame()\n",
        "            plt.show()\n",
        "\n",
        "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
        "\n",
        "    def detectaColision(self, ball_y, player_y):\n",
        "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def avanza_player(self):\n",
        "        if self.player1 + self.player_alto >= self.height_px:\n",
        "            self.player1 = self.height_px - self.player_alto\n",
        "        elif self.player1 <= -abs(self.dy):\n",
        "            self.player1 = -abs(self.dy)\n",
        "\n",
        "    def avanza_frame(self):\n",
        "        self.x += self.dx\n",
        "        self.y += self.dy\n",
        "        if self.x <= 3 or self.x > self.width_px:\n",
        "            self.dx = -self.dx\n",
        "            if self.x <= 3:\n",
        "                ret = self.detectaColision(self.y, self.player1)\n",
        "\n",
        "                if ret:\n",
        "                    self.score = 10\n",
        "                else:\n",
        "                    self.score = -10\n",
        "                    self.lives -= 1\n",
        "                    if self.lives>0:\n",
        "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "                        self.y = randint(0, self.height_px-10)\n",
        "                        self.dx = abs(self.dx)\n",
        "                        self.dy = abs(self.dy)\n",
        "        else:\n",
        "            self.score = 0\n",
        "\n",
        "        if self.y < 0 or self.y > self.height_px:\n",
        "            self.dy = -self.dy\n",
        "\n",
        "    def dibujar_frame(self):\n",
        "        fig = plt.figure(figsize=(5, 4))\n",
        "        a1 = plt.gca()\n",
        "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
        "        a1.set_ylim(-5, self.height_px+5)\n",
        "        a1.set_xlim(-5, self.width_px+5)\n",
        "\n",
        "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
        "        a1.add_patch(circle);\n",
        "        a1.add_patch(rectangle)\n",
        "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
        "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
        "        if self.lives <=0:\n",
        "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
        "        elif self.total_reward >= 1000:\n",
        "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
        "        return fig"
      ],
      "metadata": {
        "id": "tOwcCqZ2K7Zz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
        "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
        "\n",
        "    if game is None:\n",
        "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
        "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
        "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
        "\n",
        "    if learner is None:\n",
        "        print(\"Begin new Train!\")\n",
        "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
        "\n",
        "    max_points= -9999\n",
        "    first_max_reached = 0\n",
        "    total_rw=0\n",
        "    steps=[]\n",
        "\n",
        "    for played_games in range(0, rounds):\n",
        "        state = game.reset()\n",
        "        reward, done = None, None\n",
        "\n",
        "        itera=0\n",
        "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
        "            old_state = np.array(state)\n",
        "            next_action = learner.get_next_step(state, game)\n",
        "            state, reward, done = game.step(next_action, animate=animate)\n",
        "            if rounds > 1:\n",
        "                learner.update(game, old_state, next_action, reward, state, done)\n",
        "            itera+=1\n",
        "\n",
        "        steps.append(itera)\n",
        "\n",
        "        total_rw+=game.total_reward\n",
        "        if game.total_reward > max_points:\n",
        "            max_points=game.total_reward\n",
        "            first_max_reached = played_games\n",
        "\n",
        "        if played_games %500==0 and played_games >1 and not animate:\n",
        "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
        "\n",
        "    if played_games>1:\n",
        "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
        "\n",
        "    #learner.print_policy()\n",
        "\n",
        "    return learner, game"
      ],
      "metadata": {
        "id": "5FsCq00YLAXS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG5MjA1XLGWq",
        "outputId": "37f01e95-1dfc-4088-f67b-36ac7ecb7d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin new Train!\n",
            "-- Partidas[ 500 ] Avg.Puntos[ 12 ]  AVG Steps[ 211 ] Max Score[ 160 ]\n",
            "-- Partidas[ 1000 ] Avg.Puntos[ 22 ]  AVG Steps[ 245 ] Max Score[ 160 ]\n",
            "-- Partidas[ 1500 ] Avg.Puntos[ 24 ]  AVG Steps[ 254 ] Max Score[ 240 ]\n",
            "-- Partidas[ 2000 ] Avg.Puntos[ 25 ]  AVG Steps[ 255 ] Max Score[ 240 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner2 = PongAgent(game, policy=learner.get_policy())\n",
        "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
        "player = play(rounds=1, learner=learner2, game=game, animate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "efznHDUzLYOz",
        "outputId": "739fb27c-5591-46ab-e4dd-a22101f2ab58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}